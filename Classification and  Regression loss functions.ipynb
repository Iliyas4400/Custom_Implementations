{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix,F1 Score,Accuracy score,AUC_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob=[]\n",
    "y=[]\n",
    "#5000 values are randomely selected 5000 are correct(3000 as 1 and 2000 as 0)\n",
    "for i in range(5000):\n",
    "    prob.append(random.uniform(0,1))\n",
    "    y.append(random.sample([0,1],1)[0])\n",
    "for i in range(3000):\n",
    "    prob.append(random.uniform(0.5,1))\n",
    "    y.append(1)\n",
    "for i in range(2000):\n",
    "    prob.append(random.uniform(0,0.499))\n",
    "    y.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data={'proba':prob,'y':y}\n",
    "df_1=pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617878</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.258708</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456974</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974463</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba  y\n",
       "0  0.617878  0\n",
       "1  0.953692  1\n",
       "2  0.258708  0\n",
       "3  0.456974  0\n",
       "4  0.974463  0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to clculate True positive,True negative,False positivr,False negative,Precision,Recall,F1 score and accuracy\n",
    "def function(df):\n",
    "    TP=(df[(df['y']==1.0) & (df['yp']==1)].y.count())\n",
    "    FN=(df[(df['y']==1.0) & (df['yp']==0)].y.count())\n",
    "    FP=(df[(df['y']==0.0) & (df['yp']==1)].y.count())\n",
    "    TN=(df[(df['y']==0.0) & (df['yp']==0)].y.count())\n",
    "    Pre=TP/(TP+FP)\n",
    "    Re=TP/(TP+FN)\n",
    "    F1=2*Pre*Re/(Pre+Re)\n",
    "    accu=(TP+TN)/(TP+TN+FP+FN)\n",
    "    return TP,FP,TN,FN,Pre,Re,F1,accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(x):\n",
    "    if x>=0.5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp=list(map(probability,df_1['proba']))\n",
    "df_1['yp']=yp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proba</th>\n",
       "      <th>y</th>\n",
       "      <th>yp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617878</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.953692</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.258708</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.456974</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.974463</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      proba  y  yp\n",
       "0  0.617878  0   1\n",
       "1  0.953692  1   1\n",
       "2  0.258708  0   0\n",
       "3  0.456974  0   0\n",
       "4  0.974463  0   1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "[3259, 1246]\n",
      "[1259, 4236]\n",
      "******************************\n",
      "F1 score is  :  0.771795572560809\n",
      "Accuracy score is :  0.7495\n",
      "AUC score is : 0.7480794466566822\n"
     ]
    }
   ],
   "source": [
    "TP,FP,TN,FN,Pre,Re,F1,accu=function(df_1)\n",
    "print('confusion matrix')\n",
    "print([TN,FP])\n",
    "print([FN,TP])\n",
    "print('*'*30)\n",
    "print('F1 score is  : ',F1)\n",
    "print('Accuracy score is : ',accu)\n",
    "\n",
    "l2=sorted(df_1['proba'],reverse=True)#sort probability values in descending order\n",
    "t1=[]\n",
    "t2=[]\n",
    "for i in l2:#iterate through list l2\n",
    "    def p(x):#calculate yp for each threshold\n",
    "        if x>=i:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    df_1['yp']=list(map(p,df_1['proba']))     \n",
    "    TP,FP,TN,FN,Pre,Re,F1,accu=function(df_1)\n",
    "    tpr=TP/(TP+FN)\n",
    "    fpr=FP/(FP+TN)   \n",
    "    t1.append(tpr)\n",
    "    t2.append(fpr)\n",
    "print('AUC score is :',np.trapz(t1,t2))#area under the curve created by tpr and fpr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------SKLEARN Implementation-----------------\n",
      "Confusion matrix\n",
      "[[3259 1246]\n",
      " [1259 4236]]\n",
      "******************************\n",
      "F1 score is  :  0.771795572560809\n",
      "Accuracy score is :  0.7495\n",
      "AUC score is :  0.7471505222687561\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,roc_auc_score\n",
    "\n",
    "print('---------------SKLEARN Implementation-----------------')\n",
    "print('Confusion matrix')\n",
    "print(confusion_matrix(y,yp))\n",
    "print('*'*30)\n",
    "print('F1 score is  : ',f1_score(y,yp))\n",
    "print('Accuracy score is : ',accuracy_score(y,yp))\n",
    "print('AUC score is : ',roc_auc_score(y,yp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean square error,Mean absolute percentage error,R square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean square error is :  177.16569974554707\n",
      "Mean absolute percentage error is :  0.12912029940096867\n",
      "R square error is :  0.9563582786990937\n"
     ]
    }
   ],
   "source": [
    "#D\n",
    "#mean square error =average  of square of difference between actual value and predicted value \n",
    "dfd=pd.read_csv('5_d.csv')\n",
    "d=dfd['y']-dfd['pred']\n",
    "d=d*d\n",
    "ssr=np.average(d)\n",
    "print('Mean square error is : ',ssr)\n",
    "\n",
    "#mean absolute percentage error = average of absolute values of difference between actual value and predicted value\n",
    "# divided by  mean of actual values\n",
    "mape=np.average(abs(dfd['pred']-dfd['y'])/(dfd['y'].mean()))\n",
    "print('Mean absolute percentage error is : ',mape)\n",
    "\n",
    "# R square error = 1-(sse/average of square of difference between actual value and mean of actual value)\n",
    "sst=dfd['y']-(dfd['y'].mean())\n",
    "sst=np.average(sst*sst)\n",
    "r2=1-(ssr/sst)\n",
    "print('R square error is : ',r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "5_Performance_metrics_Instructions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
